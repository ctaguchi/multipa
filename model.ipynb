{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Wav2Vec2ForCTC(\n",
       "  (wav2vec2): Wav2Vec2Model(\n",
       "    (feature_extractor): Wav2Vec2FeatureEncoder(\n",
       "      (conv_layers): ModuleList(\n",
       "        (0): Wav2Vec2LayerNormConvLayer(\n",
       "          (conv): Conv1d(1, 512, kernel_size=(10,), stride=(5,))\n",
       "          (layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (activation): GELUActivation()\n",
       "        )\n",
       "        (1): Wav2Vec2LayerNormConvLayer(\n",
       "          (conv): Conv1d(512, 512, kernel_size=(3,), stride=(2,))\n",
       "          (layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (activation): GELUActivation()\n",
       "        )\n",
       "        (2): Wav2Vec2LayerNormConvLayer(\n",
       "          (conv): Conv1d(512, 512, kernel_size=(3,), stride=(2,))\n",
       "          (layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (activation): GELUActivation()\n",
       "        )\n",
       "        (3): Wav2Vec2LayerNormConvLayer(\n",
       "          (conv): Conv1d(512, 512, kernel_size=(3,), stride=(2,))\n",
       "          (layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (activation): GELUActivation()\n",
       "        )\n",
       "        (4): Wav2Vec2LayerNormConvLayer(\n",
       "          (conv): Conv1d(512, 512, kernel_size=(3,), stride=(2,))\n",
       "          (layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (activation): GELUActivation()\n",
       "        )\n",
       "        (5): Wav2Vec2LayerNormConvLayer(\n",
       "          (conv): Conv1d(512, 512, kernel_size=(2,), stride=(2,))\n",
       "          (layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (activation): GELUActivation()\n",
       "        )\n",
       "        (6): Wav2Vec2LayerNormConvLayer(\n",
       "          (conv): Conv1d(512, 512, kernel_size=(2,), stride=(2,))\n",
       "          (layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (activation): GELUActivation()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (feature_projection): Wav2Vec2FeatureProjection(\n",
       "      (layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "      (projection): Linear(in_features=512, out_features=1024, bias=True)\n",
       "      (dropout): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (encoder): Wav2Vec2EncoderStableLayerNorm(\n",
       "      (pos_conv_embed): Wav2Vec2PositionalConvEmbedding(\n",
       "        (conv): Conv1d(1024, 1024, kernel_size=(128,), stride=(1,), padding=(64,), groups=16)\n",
       "        (padding): Wav2Vec2SamePadLayer()\n",
       "        (activation): GELUActivation()\n",
       "      )\n",
       "      (layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "      (layers): ModuleList(\n",
       "        (0): Wav2Vec2EncoderLayerStableLayerNorm(\n",
       "          (attention): Wav2Vec2Attention(\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (feed_forward): Wav2Vec2FeedForward(\n",
       "            (intermediate_dropout): Dropout(p=0.0, inplace=False)\n",
       "            (intermediate_dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "            (output_dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (output_dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (1): Wav2Vec2EncoderLayerStableLayerNorm(\n",
       "          (attention): Wav2Vec2Attention(\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (feed_forward): Wav2Vec2FeedForward(\n",
       "            (intermediate_dropout): Dropout(p=0.0, inplace=False)\n",
       "            (intermediate_dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "            (output_dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (output_dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (2): Wav2Vec2EncoderLayerStableLayerNorm(\n",
       "          (attention): Wav2Vec2Attention(\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (feed_forward): Wav2Vec2FeedForward(\n",
       "            (intermediate_dropout): Dropout(p=0.0, inplace=False)\n",
       "            (intermediate_dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "            (output_dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (output_dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (3): Wav2Vec2EncoderLayerStableLayerNorm(\n",
       "          (attention): Wav2Vec2Attention(\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (feed_forward): Wav2Vec2FeedForward(\n",
       "            (intermediate_dropout): Dropout(p=0.0, inplace=False)\n",
       "            (intermediate_dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "            (output_dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (output_dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (4): Wav2Vec2EncoderLayerStableLayerNorm(\n",
       "          (attention): Wav2Vec2Attention(\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (feed_forward): Wav2Vec2FeedForward(\n",
       "            (intermediate_dropout): Dropout(p=0.0, inplace=False)\n",
       "            (intermediate_dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "            (output_dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (output_dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (5): Wav2Vec2EncoderLayerStableLayerNorm(\n",
       "          (attention): Wav2Vec2Attention(\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (feed_forward): Wav2Vec2FeedForward(\n",
       "            (intermediate_dropout): Dropout(p=0.0, inplace=False)\n",
       "            (intermediate_dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "            (output_dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (output_dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (6): Wav2Vec2EncoderLayerStableLayerNorm(\n",
       "          (attention): Wav2Vec2Attention(\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (feed_forward): Wav2Vec2FeedForward(\n",
       "            (intermediate_dropout): Dropout(p=0.0, inplace=False)\n",
       "            (intermediate_dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "            (output_dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (output_dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (7): Wav2Vec2EncoderLayerStableLayerNorm(\n",
       "          (attention): Wav2Vec2Attention(\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (feed_forward): Wav2Vec2FeedForward(\n",
       "            (intermediate_dropout): Dropout(p=0.0, inplace=False)\n",
       "            (intermediate_dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "            (output_dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (output_dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (8): Wav2Vec2EncoderLayerStableLayerNorm(\n",
       "          (attention): Wav2Vec2Attention(\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (feed_forward): Wav2Vec2FeedForward(\n",
       "            (intermediate_dropout): Dropout(p=0.0, inplace=False)\n",
       "            (intermediate_dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "            (output_dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (output_dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (9): Wav2Vec2EncoderLayerStableLayerNorm(\n",
       "          (attention): Wav2Vec2Attention(\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (feed_forward): Wav2Vec2FeedForward(\n",
       "            (intermediate_dropout): Dropout(p=0.0, inplace=False)\n",
       "            (intermediate_dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "            (output_dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (output_dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (10): Wav2Vec2EncoderLayerStableLayerNorm(\n",
       "          (attention): Wav2Vec2Attention(\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (feed_forward): Wav2Vec2FeedForward(\n",
       "            (intermediate_dropout): Dropout(p=0.0, inplace=False)\n",
       "            (intermediate_dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "            (output_dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (output_dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (11): Wav2Vec2EncoderLayerStableLayerNorm(\n",
       "          (attention): Wav2Vec2Attention(\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (feed_forward): Wav2Vec2FeedForward(\n",
       "            (intermediate_dropout): Dropout(p=0.0, inplace=False)\n",
       "            (intermediate_dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "            (output_dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (output_dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (12): Wav2Vec2EncoderLayerStableLayerNorm(\n",
       "          (attention): Wav2Vec2Attention(\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (feed_forward): Wav2Vec2FeedForward(\n",
       "            (intermediate_dropout): Dropout(p=0.0, inplace=False)\n",
       "            (intermediate_dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "            (output_dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (output_dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (13): Wav2Vec2EncoderLayerStableLayerNorm(\n",
       "          (attention): Wav2Vec2Attention(\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (feed_forward): Wav2Vec2FeedForward(\n",
       "            (intermediate_dropout): Dropout(p=0.0, inplace=False)\n",
       "            (intermediate_dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "            (output_dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (output_dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (14): Wav2Vec2EncoderLayerStableLayerNorm(\n",
       "          (attention): Wav2Vec2Attention(\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (feed_forward): Wav2Vec2FeedForward(\n",
       "            (intermediate_dropout): Dropout(p=0.0, inplace=False)\n",
       "            (intermediate_dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "            (output_dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (output_dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (15): Wav2Vec2EncoderLayerStableLayerNorm(\n",
       "          (attention): Wav2Vec2Attention(\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (feed_forward): Wav2Vec2FeedForward(\n",
       "            (intermediate_dropout): Dropout(p=0.0, inplace=False)\n",
       "            (intermediate_dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "            (output_dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (output_dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (16): Wav2Vec2EncoderLayerStableLayerNorm(\n",
       "          (attention): Wav2Vec2Attention(\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (feed_forward): Wav2Vec2FeedForward(\n",
       "            (intermediate_dropout): Dropout(p=0.0, inplace=False)\n",
       "            (intermediate_dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "            (output_dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (output_dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (17): Wav2Vec2EncoderLayerStableLayerNorm(\n",
       "          (attention): Wav2Vec2Attention(\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (feed_forward): Wav2Vec2FeedForward(\n",
       "            (intermediate_dropout): Dropout(p=0.0, inplace=False)\n",
       "            (intermediate_dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "            (output_dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (output_dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (18): Wav2Vec2EncoderLayerStableLayerNorm(\n",
       "          (attention): Wav2Vec2Attention(\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (feed_forward): Wav2Vec2FeedForward(\n",
       "            (intermediate_dropout): Dropout(p=0.0, inplace=False)\n",
       "            (intermediate_dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "            (output_dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (output_dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (19): Wav2Vec2EncoderLayerStableLayerNorm(\n",
       "          (attention): Wav2Vec2Attention(\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (feed_forward): Wav2Vec2FeedForward(\n",
       "            (intermediate_dropout): Dropout(p=0.0, inplace=False)\n",
       "            (intermediate_dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "            (output_dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (output_dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (20): Wav2Vec2EncoderLayerStableLayerNorm(\n",
       "          (attention): Wav2Vec2Attention(\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (feed_forward): Wav2Vec2FeedForward(\n",
       "            (intermediate_dropout): Dropout(p=0.0, inplace=False)\n",
       "            (intermediate_dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "            (output_dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (output_dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (21): Wav2Vec2EncoderLayerStableLayerNorm(\n",
       "          (attention): Wav2Vec2Attention(\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (feed_forward): Wav2Vec2FeedForward(\n",
       "            (intermediate_dropout): Dropout(p=0.0, inplace=False)\n",
       "            (intermediate_dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "            (output_dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (output_dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (22): Wav2Vec2EncoderLayerStableLayerNorm(\n",
       "          (attention): Wav2Vec2Attention(\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (feed_forward): Wav2Vec2FeedForward(\n",
       "            (intermediate_dropout): Dropout(p=0.0, inplace=False)\n",
       "            (intermediate_dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "            (output_dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (output_dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (23): Wav2Vec2EncoderLayerStableLayerNorm(\n",
       "          (attention): Wav2Vec2Attention(\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (feed_forward): Wav2Vec2FeedForward(\n",
       "            (intermediate_dropout): Dropout(p=0.0, inplace=False)\n",
       "            (intermediate_dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "            (output_dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (output_dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.0, inplace=False)\n",
       "  (lm_head): Linear(in_features=1024, out_features=301, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import Wav2Vec2Processor, Wav2Vec2ForCTC\n",
    "from datasets import load_dataset\n",
    "import jiwer\n",
    "import numpy as np\n",
    "import gc \n",
    "import librosa\n",
    "import os \n",
    "\n",
    "# model_dir = \"/mnt/5fc7fd01-6487-4f39-8109-556023ff1f7f/puc/7 sem/topicos/multipa/wav2vec2-large-xlsr-japlmthufiel-ipajaplmthufielta-nq-ns/checkpoint-100\"\n",
    "model_dir=\"/mnt/5fc7fd01-6487-4f39-8109-556023ff1f7f/puc/7 sem/topicos/multipa/wav2vec2-large-xlsr-japlmthufiel-ipajaplmthufielta-nq-ns\"\n",
    "# model_dir = \"/mnt/5fc7fd01-6487-4f39-8109-556023ff1f7f/puc/7 sem/topicos/multipa/wav2vec2-large-xlsr-japlmthufielta-ipa1000-ns\"\n",
    "\n",
    "#pegar vocab.json da raiz e copia-lo pro wav2vec2-large-xlsr-japlmthufiel-ipajaplmthufielta-nq-ns\n",
    "\n",
    "processor = Wav2Vec2Processor.from_pretrained(model_dir)\n",
    "model = Wav2Vec2ForCTC.from_pretrained(model_dir)\n",
    "cache_dir = './cache'\n",
    "\n",
    "model.eval()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import librosa\n",
    "from transformers import Wav2Vec2Processor, Wav2Vec2ForCTC\n",
    "import torch\n",
    "\n",
    "# Carregar o processador e o modelo\n",
    "model_dir = \"/mnt/5fc7fd01-6487-4f39-8109-556023ff1f7f/puc/7 sem/topicos/multipa/wav2vec2-large-xlsr-japlmthufiel-ipajaplmthufielta-nq-ns\"\n",
    "os.getenv('CAC')\n",
    "\n",
    "\n",
    "processor = Wav2Vec2Processor.from_pretrained(model_dir)\n",
    "model = Wav2Vec2ForCTC.from_pretrained(model_dir)\n",
    "model.eval()\n",
    "\n",
    "# Função para carregar e processar o áudio\n",
    "def load_and_process_audio(audio_path, target_sampling_rate=16000):\n",
    "    audio, sr = librosa.load(audio_path, sr=None)  # Carregar o áudio\n",
    "    print(f\"Sampling rate do áudio: {sr}\")  # Verificar a taxa de amostragem\n",
    "    if sr != target_sampling_rate:\n",
    "        print(f\"Reamostrando o áudio para {target_sampling_rate}Hz\")  # Exibir reamostragem\n",
    "        audio = librosa.resample(audio, orig_sr=sr, target_sr=target_sampling_rate)  # Reamostrar se necessário\n",
    "    return audio\n",
    "\n",
    "# Função para transcrever o áudio para IPA\n",
    "def transcribe_audio_to_ipa(audio_path):\n",
    "    # Carregar e processar o áudio\n",
    "    audio = load_and_process_audio(audio_path)\n",
    "\n",
    "    # Verificar se o áudio tem o tamanho adequado para o modelo\n",
    "    print(f\"Tamanho do áudio (número de amostras): {len(audio)}\")\n",
    "\n",
    "    # Processar o áudio para o modelo\n",
    "    input_values = processor(audio, return_tensors=\"pt\", sampling_rate=16000).input_values\n",
    "    print(input_values)\n",
    "\n",
    "    # Verificar a forma do tensor de entrada\n",
    "    print(f\"Forma do tensor de entrada: {input_values.shape}\")\n",
    "\n",
    "    # Fazer a predição\n",
    "    with torch.no_grad():\n",
    "        logits = model(input_values).logits\n",
    "    print(logits)\n",
    "\n",
    "    # Obter os índices das previsões\n",
    "    predicted_ids = torch.argmax(logits, dim=-1)\n",
    "    print(predicted_ids)\n",
    "\n",
    "    # Decodificar para IPA (usando o processor.decode diretamente)\n",
    "    transcription = processor.decode(predicted_ids[0])  # Usando o método decode diretamente no primeiro item\n",
    "\n",
    "    return transcription\n",
    "\n",
    "# Caminho da pasta contendo os arquivos de áudio\n",
    "audio_folder = '/mnt/5fc7fd01-6487-4f39-8109-556023ff1f7f/puc/7 sem/topicos/multipa/cache/downloads/extracted/'\n",
    "\n",
    "# Iterar sobre todos os arquivos de áudio na pasta\n",
    "for filename in os.listdir(audio_folder):\n",
    "    if filename.endswith(\".mp3\"):  # Verificar se é um arquivo mp3\n",
    "        audio_path = os.path.join(audio_folder, filename)\n",
    "        print(f\"Processando arquivo: {filename}\")\n",
    "        \n",
    "        # Transcrever o áudio\n",
    "        ipa_transcription = transcribe_audio_to_ipa(audio_path)\n",
    "\n",
    "        # Exibir a transcrição IPA\n",
    "        print(f\"Transcrição IPA para {filename}: {ipa_transcription}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processando arquivo: common_voice_ja_32421686.mp3\n",
      "Sampling rate do áudio: 32000\n",
      "Reamostrando o áudio para 16000Hz\n",
      "Tamanho do áudio (número de amostras): 112320\n",
      "tensor([[0.0002, 0.0002, 0.0002,  ..., 0.0002, 0.0002, 0.0002]])\n",
      "Forma do tensor de entrada: torch.Size([1, 112320])\n",
      "logits:  tensor([[[-0.7411, -0.5865, -0.5853,  ..., -0.9725, -0.9877,  5.1098],\n",
      "         [-0.7519, -0.6079, -0.5937,  ..., -0.9558, -0.9867,  5.1225],\n",
      "         [-0.7545, -0.6072, -0.5875,  ..., -0.9328, -1.0163,  5.1364],\n",
      "         ...,\n",
      "         [-0.7533, -0.5968, -0.5863,  ..., -0.9473, -1.0130,  5.1442],\n",
      "         [-0.7477, -0.6008, -0.5937,  ..., -0.9481, -1.0173,  5.1409],\n",
      "         [-0.7471, -0.5950, -0.5829,  ..., -0.9518, -1.0144,  5.1376]]])\n",
      "predicted_ids:  tensor([[300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300,\n",
      "         300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300,\n",
      "         300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300,\n",
      "         300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300,\n",
      "         300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300,\n",
      "         300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300,\n",
      "         300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300,\n",
      "         300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300,\n",
      "         300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300,\n",
      "         300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300,\n",
      "         300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300,\n",
      "         300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300,\n",
      "         300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300,\n",
      "         300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300,\n",
      "         300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300,\n",
      "         300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300,\n",
      "         300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300,\n",
      "         300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300,\n",
      "         300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300,\n",
      "         300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300,\n",
      "         300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300,\n",
      "         300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300,\n",
      "         300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300,\n",
      "         300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300,\n",
      "         300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300]])\n",
      "Transcrição IPA para common_voice_ja_32421686.mp3: [PAD]\n",
      "\n",
      "[PAD]\n",
      "Processando arquivo: common_voice_ja_25943571.mp3\n",
      "Sampling rate do áudio: 32000\n",
      "Reamostrando o áudio para 16000Hz\n",
      "Tamanho do áudio (número de amostras): 144000\n",
      "tensor([[0.0001, 0.0001, 0.0001,  ..., 0.0001, 0.0001, 0.0001]])\n",
      "Forma do tensor de entrada: torch.Size([1, 144000])\n",
      "logits:  tensor([[[-0.7408, -0.5834, -0.5854,  ..., -0.9723, -0.9846,  5.1038],\n",
      "         [-0.7499, -0.6076, -0.6004,  ..., -0.9669, -0.9976,  5.1244],\n",
      "         [-0.7572, -0.6102, -0.5945,  ..., -0.9603, -0.9958,  5.1310],\n",
      "         ...,\n",
      "         [-0.7578, -0.5920, -0.5927,  ..., -0.9598, -1.0090,  5.1422],\n",
      "         [-0.7549, -0.5898, -0.5911,  ..., -0.9521, -1.0165,  5.1431],\n",
      "         [-0.7487, -0.5892, -0.5889,  ..., -0.9576, -1.0117,  5.1373]]])\n",
      "predicted_ids:  tensor([[300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300,\n",
      "         300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300,\n",
      "         300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300,\n",
      "         300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300,\n",
      "         300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300,\n",
      "         300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300,\n",
      "         300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300,\n",
      "         300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300,\n",
      "         300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300,\n",
      "         300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300,\n",
      "         300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300,\n",
      "         300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300,\n",
      "         300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300,\n",
      "         300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300,\n",
      "         300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300,\n",
      "         300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300,\n",
      "         300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300,\n",
      "         300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300,\n",
      "         300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300,\n",
      "         300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300,\n",
      "         300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300,\n",
      "         300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300,\n",
      "         300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300,\n",
      "         300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300,\n",
      "         300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300,\n",
      "         300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300,\n",
      "         300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300,\n",
      "         300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300,\n",
      "         300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300,\n",
      "         300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300,\n",
      "         300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300,\n",
      "         300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300,\n",
      "         300]])\n",
      "Transcrição IPA para common_voice_ja_25943571.mp3: [PAD]\n",
      "\n",
      "[PAD]\n",
      "Processando arquivo: common_voice_ja_21573728.mp3\n",
      "Sampling rate do áudio: 48000\n",
      "Reamostrando o áudio para 16000Hz\n",
      "Tamanho do áudio (número de amostras): 66432\n",
      "tensor([[2.3477e-04, 2.3477e-04, 2.3477e-04,  ..., 1.6903e-05, 1.0083e-03,\n",
      "         6.2695e-04]])\n",
      "Forma do tensor de entrada: torch.Size([1, 66432])\n",
      "logits:  tensor([[[-0.7467, -0.5931, -0.5774,  ..., -0.9737, -0.9950,  5.1205],\n",
      "         [-0.7471, -0.6168, -0.5915,  ..., -0.9740, -1.0057,  5.1317],\n",
      "         [-0.7518, -0.6177, -0.5918,  ..., -0.9685, -1.0084,  5.1334],\n",
      "         ...,\n",
      "         [-0.7437, -0.6111, -0.5673,  ..., -0.9614, -1.0094,  5.1415],\n",
      "         [-0.7480, -0.6152, -0.5662,  ..., -0.9629, -1.0073,  5.1434],\n",
      "         [-0.7222, -0.6007, -0.5668,  ..., -0.9546, -1.0061,  5.1323]]])\n",
      "predicted_ids:  tensor([[300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300,\n",
      "         300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300,\n",
      "         300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300,\n",
      "         300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300,\n",
      "         300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300,\n",
      "         300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300,\n",
      "         300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300,\n",
      "         300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300,\n",
      "         300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300,\n",
      "         300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300,\n",
      "         300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300,\n",
      "         300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300,\n",
      "         300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300,\n",
      "         300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300,\n",
      "         300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300]])\n",
      "Transcrição IPA para common_voice_ja_21573728.mp3: [PAD]\n",
      "\n",
      "[PAD]\n",
      "Processando arquivo: common_voice_ja_26310911.mp3\n",
      "Sampling rate do áudio: 32000\n",
      "Reamostrando o áudio para 16000Hz\n",
      "Tamanho do áudio (número de amostras): 53568\n",
      "tensor([[ 0.0003,  0.0003,  0.0003,  ..., -0.0002, -0.0007,  0.0003]])\n",
      "Forma do tensor de entrada: torch.Size([1, 53568])\n",
      "logits:  tensor([[[-0.7519, -0.5931, -0.5762,  ..., -0.9689, -0.9926,  5.1169],\n",
      "         [-0.7486, -0.6191, -0.5709,  ..., -0.9468, -0.9922,  5.1198],\n",
      "         [-0.7433, -0.6221, -0.5695,  ..., -0.9444, -0.9962,  5.1336],\n",
      "         ...,\n",
      "         [-0.7356, -0.6053, -0.5704,  ..., -0.9600, -0.9990,  5.1399],\n",
      "         [-0.7349, -0.6055, -0.5718,  ..., -0.9590, -1.0057,  5.1412],\n",
      "         [-0.7388, -0.6121, -0.5585,  ..., -0.9625, -1.0037,  5.1333]]])\n",
      "predicted_ids:  tensor([[300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300,\n",
      "         300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300,\n",
      "         300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300,\n",
      "         300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300,\n",
      "         300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300,\n",
      "         300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300,\n",
      "         300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300,\n",
      "         300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300,\n",
      "         300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300,\n",
      "         300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300,\n",
      "         300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300,\n",
      "         300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300]])\n",
      "Transcrição IPA para common_voice_ja_26310911.mp3: [PAD]\n",
      "\n",
      "[PAD]\n",
      "Processando arquivo: common_voice_ja_25786925.mp3\n",
      "Sampling rate do áudio: 32000\n",
      "Reamostrando o áudio para 16000Hz\n",
      "Tamanho do áudio (número de amostras): 60480\n",
      "tensor([[-0.0002, -0.0002, -0.0002,  ..., -0.0002, -0.0002, -0.0002]])\n",
      "Forma do tensor de entrada: torch.Size([1, 60480])\n",
      "logits:  tensor([[[-0.7451, -0.5921, -0.5769,  ..., -0.9706, -0.9956,  5.1222],\n",
      "         [-0.7494, -0.6112, -0.5915,  ..., -0.9707, -1.0059,  5.1352],\n",
      "         [-0.7543, -0.6162, -0.5887,  ..., -0.9683, -1.0054,  5.1365],\n",
      "         ...,\n",
      "         [-0.7380, -0.6035, -0.5669,  ..., -0.9504, -0.9985,  5.1403],\n",
      "         [-0.7361, -0.6214, -0.5679,  ..., -0.9575, -1.0000,  5.1408],\n",
      "         [-0.7563, -0.6203, -0.5746,  ..., -0.9484, -1.0130,  5.1305]]])\n",
      "predicted_ids:  tensor([[300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300,\n",
      "         300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300,\n",
      "         300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300,\n",
      "         300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300,\n",
      "         300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300,\n",
      "         300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300,\n",
      "         300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300,\n",
      "         300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300,\n",
      "         300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300,\n",
      "         300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300,\n",
      "         300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300,\n",
      "         300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300,\n",
      "         300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300,\n",
      "         300, 300, 300, 300, 300, 300]])\n",
      "Transcrição IPA para common_voice_ja_25786925.mp3: [PAD]\n",
      "\n",
      "[PAD]\n",
      "Processando arquivo: common_voice_ja_27695103.mp3\n",
      "Sampling rate do áudio: 32000\n",
      "Reamostrando o áudio para 16000Hz\n",
      "Tamanho do áudio (número de amostras): 77760\n",
      "tensor([[-1.4738e-04, -1.4738e-04, -1.4738e-04,  ..., -2.2562e-04,\n",
      "         -1.5324e-04, -9.5074e-06]])\n",
      "Forma do tensor de entrada: torch.Size([1, 77760])\n",
      "logits:  tensor([[[-0.7546, -0.5978, -0.5796,  ..., -0.9760, -0.9944,  5.1159],\n",
      "         [-0.7524, -0.6231, -0.5775,  ..., -0.9602, -0.9886,  5.1212],\n",
      "         [-0.7310, -0.6148, -0.5734,  ..., -0.9449, -0.9949,  5.1295],\n",
      "         ...,\n",
      "         [-0.7358, -0.6067, -0.5698,  ..., -0.9515, -1.0103,  5.1367],\n",
      "         [-0.7334, -0.5997, -0.5621,  ..., -0.9376, -1.0177,  5.1344],\n",
      "         [-0.7363, -0.6132, -0.5710,  ..., -0.9574, -1.0159,  5.1319]]])\n",
      "predicted_ids:  tensor([[300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300,\n",
      "         300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300,\n",
      "         300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300,\n",
      "         300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300,\n",
      "         300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300,\n",
      "         300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300,\n",
      "         300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300,\n",
      "         300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300,\n",
      "         300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300,\n",
      "         300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300,\n",
      "         300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300,\n",
      "         300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300,\n",
      "         300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300,\n",
      "         300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300,\n",
      "         300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300,\n",
      "         300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300,\n",
      "         300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300,\n",
      "         300, 300, 300, 300]])\n",
      "Transcrição IPA para common_voice_ja_27695103.mp3: [PAD]\n",
      "\n",
      "[PAD]\n",
      "Processando arquivo: common_voice_ja_27696236.mp3\n",
      "Sampling rate do áudio: 32000\n",
      "Reamostrando o áudio para 16000Hz\n",
      "Tamanho do áudio (número de amostras): 79488\n",
      "tensor([[0.0006, 0.0006, 0.0006,  ..., 0.0001, 0.0007, 0.0004]])\n",
      "Forma do tensor de entrada: torch.Size([1, 79488])\n",
      "logits:  tensor([[[-0.7473, -0.5997, -0.5750,  ..., -0.9739, -0.9943,  5.1213],\n",
      "         [-0.7446, -0.6160, -0.5743,  ..., -0.9596, -0.9883,  5.1209],\n",
      "         [-0.7404, -0.6230, -0.5747,  ..., -0.9542, -0.9911,  5.1335],\n",
      "         ...,\n",
      "         [-0.7445, -0.6139, -0.5687,  ..., -0.9564, -1.0038,  5.1393],\n",
      "         [-0.7464, -0.6109, -0.5583,  ..., -0.9596, -0.9998,  5.1425],\n",
      "         [-0.7363, -0.6161, -0.5603,  ..., -0.9606, -1.0051,  5.1321]]])\n",
      "predicted_ids:  tensor([[300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300,\n",
      "         300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300,\n",
      "         300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300,\n",
      "         300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300,\n",
      "         300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300,\n",
      "         300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300,\n",
      "         300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300,\n",
      "         300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300,\n",
      "         300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300,\n",
      "         300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300,\n",
      "         300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300,\n",
      "         300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300,\n",
      "         300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300,\n",
      "         300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300,\n",
      "         300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300,\n",
      "         300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300,\n",
      "         300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300,\n",
      "         300, 300, 300, 300, 300, 300, 300, 300, 300, 300]])\n",
      "Transcrição IPA para common_voice_ja_27696236.mp3: [PAD]\n",
      "\n",
      "[PAD]\n",
      "Processando arquivo: common_voice_ja_24976027.mp3\n",
      "Sampling rate do áudio: 32000\n",
      "Reamostrando o áudio para 16000Hz\n",
      "Tamanho do áudio (número de amostras): 104256\n",
      "tensor([[0.0005, 0.0005, 0.0005,  ..., 0.0006, 0.0006, 0.0003]])\n",
      "Forma do tensor de entrada: torch.Size([1, 104256])\n",
      "logits:  tensor([[[-0.7465, -0.5917, -0.5813,  ..., -0.9696, -0.9891,  5.1094],\n",
      "         [-0.7496, -0.6046, -0.5866,  ..., -0.9523, -0.9868,  5.1189],\n",
      "         [-0.7436, -0.6009, -0.5772,  ..., -0.9479, -0.9969,  5.1342],\n",
      "         ...,\n",
      "         [-0.7547, -0.6003, -0.5742,  ..., -0.9625, -1.0130,  5.1393],\n",
      "         [-0.7476, -0.5988, -0.5753,  ..., -0.9594, -1.0148,  5.1410],\n",
      "         [-0.7425, -0.5941, -0.5751,  ..., -0.9526, -1.0201,  5.1351]]])\n",
      "predicted_ids:  tensor([[300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300,\n",
      "         300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300,\n",
      "         300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300,\n",
      "         300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300,\n",
      "         300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300,\n",
      "         300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300,\n",
      "         300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300,\n",
      "         300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300,\n",
      "         300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300,\n",
      "         300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300,\n",
      "         300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300,\n",
      "         300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300,\n",
      "         300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300,\n",
      "         300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300,\n",
      "         300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300,\n",
      "         300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300,\n",
      "         300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300,\n",
      "         300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300,\n",
      "         300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300,\n",
      "         300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300,\n",
      "         300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300,\n",
      "         300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300,\n",
      "         300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300,\n",
      "         300, 300, 300]])\n",
      "Transcrição IPA para common_voice_ja_24976027.mp3: [PAD]\n",
      "\n",
      "[PAD]\n",
      "Processando arquivo: common_voice_ja_30707477.mp3\n",
      "Sampling rate do áudio: 32000\n",
      "Reamostrando o áudio para 16000Hz\n",
      "Tamanho do áudio (número de amostras): 62208\n",
      "tensor([[0.0003, 0.0003, 0.0003,  ..., 0.0002, 0.0004, 0.0003]])\n",
      "Forma do tensor de entrada: torch.Size([1, 62208])\n",
      "logits:  tensor([[[-0.7482, -0.5938, -0.5836,  ..., -0.9734, -0.9923,  5.1163],\n",
      "         [-0.7448, -0.6185, -0.5912,  ..., -0.9592, -0.9924,  5.1294],\n",
      "         [-0.7358, -0.6193, -0.5759,  ..., -0.9553, -1.0018,  5.1390],\n",
      "         ...,\n",
      "         [-0.7532, -0.6011, -0.5736,  ..., -0.9592, -1.0188,  5.1483],\n",
      "         [-0.7526, -0.6084, -0.5703,  ..., -0.9568, -1.0178,  5.1451],\n",
      "         [-0.7472, -0.6091, -0.5762,  ..., -0.9513, -1.0111,  5.1342]]])\n",
      "predicted_ids:  tensor([[300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300,\n",
      "         300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300,\n",
      "         300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300,\n",
      "         300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300,\n",
      "         300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300,\n",
      "         300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300,\n",
      "         300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300,\n",
      "         300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300,\n",
      "         300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300,\n",
      "         300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300,\n",
      "         300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300,\n",
      "         300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300,\n",
      "         300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300,\n",
      "         300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300]])\n",
      "Transcrição IPA para common_voice_ja_30707477.mp3: [PAD]\n",
      "\n",
      "[PAD]\n",
      "Processando arquivo: common_voice_ja_27690685.mp3\n",
      "Sampling rate do áudio: 32000\n",
      "Reamostrando o áudio para 16000Hz\n",
      "Tamanho do áudio (número de amostras): 135360\n",
      "tensor([[-5.7129e-05, -5.7129e-05, -5.7129e-05,  ..., -6.6804e-05,\n",
      "         -4.5148e-05, -3.0985e-05]])\n",
      "Forma do tensor de entrada: torch.Size([1, 135360])\n",
      "logits:  tensor([[[-0.7361, -0.5891, -0.5869,  ..., -0.9758, -0.9859,  5.1070],\n",
      "         [-0.7516, -0.6146, -0.5927,  ..., -0.9677, -0.9870,  5.1181],\n",
      "         [-0.7454, -0.6201, -0.5780,  ..., -0.9459, -1.0126,  5.1317],\n",
      "         ...,\n",
      "         [-0.7561, -0.6008, -0.5766,  ..., -0.9614, -1.0204,  5.1422],\n",
      "         [-0.7510, -0.6016, -0.5745,  ..., -0.9647, -1.0172,  5.1431],\n",
      "         [-0.7424, -0.5912, -0.5779,  ..., -0.9572, -1.0181,  5.1392]]])\n",
      "predicted_ids:  tensor([[300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300,\n",
      "         300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300,\n",
      "         300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300,\n",
      "         300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300,\n",
      "         300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300,\n",
      "         300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300,\n",
      "         300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300,\n",
      "         300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300,\n",
      "         300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300,\n",
      "         300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300,\n",
      "         300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300,\n",
      "         300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300,\n",
      "         300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300,\n",
      "         300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300,\n",
      "         300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300,\n",
      "         300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300,\n",
      "         300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300,\n",
      "         300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300,\n",
      "         300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300,\n",
      "         300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300,\n",
      "         300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300,\n",
      "         300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300,\n",
      "         300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300,\n",
      "         300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300,\n",
      "         300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300,\n",
      "         300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300,\n",
      "         300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300,\n",
      "         300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300,\n",
      "         300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300,\n",
      "         300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300,\n",
      "         300, 300]])\n",
      "Transcrição IPA para common_voice_ja_27690685.mp3: [PAD]\n",
      "\n",
      "[PAD]\n",
      "Processando arquivo: common_voice_ja_33231791.mp3\n",
      "Sampling rate do áudio: 32000\n",
      "Reamostrando o áudio para 16000Hz\n",
      "Tamanho do áudio (número de amostras): 65088\n",
      "tensor([[0.0002, 0.0002, 0.0002,  ..., 0.0002, 0.0019, 0.0015]])\n",
      "Forma do tensor de entrada: torch.Size([1, 65088])\n",
      "logits:  tensor([[[-0.7403, -0.5896, -0.5753,  ..., -0.9649, -0.9954,  5.1149],\n",
      "         [-0.7500, -0.6132, -0.5762,  ..., -0.9570, -0.9930,  5.1280],\n",
      "         [-0.7523, -0.6180, -0.5733,  ..., -0.9547, -1.0085,  5.1362],\n",
      "         ...,\n",
      "         [-0.7480, -0.5895, -0.5703,  ..., -0.9513, -1.0027,  5.1410],\n",
      "         [-0.7498, -0.5931, -0.5642,  ..., -0.9526, -1.0017,  5.1419],\n",
      "         [-0.7405, -0.6082, -0.5598,  ..., -0.9555, -1.0006,  5.1318]]])\n",
      "predicted_ids:  tensor([[300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300,\n",
      "         300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300,\n",
      "         300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300,\n",
      "         300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300,\n",
      "         300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300,\n",
      "         300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300,\n",
      "         300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300,\n",
      "         300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300,\n",
      "         300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300,\n",
      "         300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300,\n",
      "         300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300,\n",
      "         300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300,\n",
      "         300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300,\n",
      "         300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300,\n",
      "         300, 300, 300, 300, 300, 300, 300]])\n",
      "Transcrição IPA para common_voice_ja_33231791.mp3: [PAD]\n",
      "\n",
      "[PAD]\n",
      "Processando arquivo: common_voice_ja_27224466.mp3\n",
      "Sampling rate do áudio: 32000\n",
      "Reamostrando o áudio para 16000Hz\n",
      "Tamanho do áudio (número de amostras): 145728\n",
      "tensor([[7.3248e-05, 7.3248e-05, 7.3248e-05,  ..., 1.6623e-04, 8.3946e-05,\n",
      "         1.1046e-04]])\n",
      "Forma do tensor de entrada: torch.Size([1, 145728])\n",
      "logits:  tensor([[[-0.7504, -0.5821, -0.5817,  ..., -0.9751, -0.9842,  5.1006],\n",
      "         [-0.7523, -0.6244, -0.5787,  ..., -0.9602, -0.9713,  5.0955],\n",
      "         [-0.7401, -0.6107, -0.5678,  ..., -0.9523, -0.9944,  5.1275],\n",
      "         ...,\n",
      "         [-0.7379, -0.5989, -0.5714,  ..., -0.9558, -0.9935,  5.1379],\n",
      "         [-0.7388, -0.6015, -0.5765,  ..., -0.9580, -1.0021,  5.1353],\n",
      "         [-0.7410, -0.6069, -0.5813,  ..., -0.9585, -0.9977,  5.1271]]])\n",
      "predicted_ids:  tensor([[300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300,\n",
      "         300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300,\n",
      "         300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300,\n",
      "         300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300,\n",
      "         300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300,\n",
      "         300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300,\n",
      "         300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300,\n",
      "         300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300,\n",
      "         300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300,\n",
      "         300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300,\n",
      "         300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300,\n",
      "         300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300,\n",
      "         300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300,\n",
      "         300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300,\n",
      "         300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300,\n",
      "         300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300,\n",
      "         300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300,\n",
      "         300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300,\n",
      "         300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300,\n",
      "         300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300,\n",
      "         300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300,\n",
      "         300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300,\n",
      "         300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300,\n",
      "         300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300,\n",
      "         300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300,\n",
      "         300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300,\n",
      "         300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300,\n",
      "         300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300,\n",
      "         300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300,\n",
      "         300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300,\n",
      "         300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300,\n",
      "         300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300,\n",
      "         300, 300, 300, 300, 300, 300, 300]])\n",
      "Transcrição IPA para common_voice_ja_27224466.mp3: [PAD]\n",
      "\n",
      "[PAD]\n",
      "Processando arquivo: common_voice_ja_26466490.mp3\n",
      "Sampling rate do áudio: 32000\n",
      "Reamostrando o áudio para 16000Hz\n",
      "Tamanho do áudio (número de amostras): 115200\n",
      "tensor([[-4.6159e-05, -4.6158e-05, -4.6158e-05,  ..., -6.1674e-05,\n",
      "         -6.9459e-05, -6.6347e-05]])\n",
      "Forma do tensor de entrada: torch.Size([1, 115200])\n",
      "logits:  tensor([[[-0.7466, -0.5867, -0.5883,  ..., -0.9683, -0.9940,  5.1062],\n",
      "         [-0.7434, -0.6143, -0.5882,  ..., -0.9634, -1.0070,  5.1344],\n",
      "         [-0.7428, -0.6296, -0.5810,  ..., -0.9376, -1.0007,  5.1226],\n",
      "         ...,\n",
      "         [-0.7494, -0.6073, -0.5841,  ..., -0.9538, -1.0100,  5.1415],\n",
      "         [-0.7505, -0.5957, -0.5767,  ..., -0.9505, -1.0089,  5.1392],\n",
      "         [-0.7364, -0.6148, -0.5748,  ..., -0.9539, -1.0066,  5.1295]]])\n",
      "predicted_ids:  tensor([[300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300,\n",
      "         300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300,\n",
      "         300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300,\n",
      "         300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300,\n",
      "         300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300,\n",
      "         300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300,\n",
      "         300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300,\n",
      "         300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300,\n",
      "         300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300,\n",
      "         300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300,\n",
      "         300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300,\n",
      "         300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300,\n",
      "         300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300,\n",
      "         300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300,\n",
      "         300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300,\n",
      "         300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300,\n",
      "         300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300,\n",
      "         300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300,\n",
      "         300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300,\n",
      "         300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300,\n",
      "         300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300,\n",
      "         300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300,\n",
      "         300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300,\n",
      "         300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300,\n",
      "         300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300,\n",
      "         300, 300, 300, 300, 300, 300, 300, 300, 300]])\n",
      "Transcrição IPA para common_voice_ja_26466490.mp3: [PAD]\n",
      "\n",
      "[PAD]\n",
      "Processando arquivo: common_voice_ja_27816598.mp3\n",
      "Sampling rate do áudio: 32000\n",
      "Reamostrando o áudio para 16000Hz\n",
      "Tamanho do áudio (número de amostras): 54720\n",
      "tensor([[-0.0002, -0.0002, -0.0002,  ..., -0.0002, -0.0002, -0.0002]])\n",
      "Forma do tensor de entrada: torch.Size([1, 54720])\n",
      "logits:  tensor([[[-0.7447, -0.5894, -0.5853,  ..., -0.9742, -0.9863,  5.1192],\n",
      "         [-0.7580, -0.6114, -0.5894,  ..., -0.9656, -0.9955,  5.1347],\n",
      "         [-0.7561, -0.6017, -0.5912,  ..., -0.9484, -1.0087,  5.1454],\n",
      "         ...,\n",
      "         [-0.7586, -0.5887, -0.5875,  ..., -0.9483, -1.0182,  5.1473],\n",
      "         [-0.7576, -0.5903, -0.5919,  ..., -0.9521, -1.0155,  5.1475],\n",
      "         [-0.7532, -0.5916, -0.5850,  ..., -0.9601, -1.0151,  5.1412]]])\n",
      "predicted_ids:  tensor([[300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300,\n",
      "         300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300,\n",
      "         300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300,\n",
      "         300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300,\n",
      "         300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300,\n",
      "         300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300,\n",
      "         300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300,\n",
      "         300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300,\n",
      "         300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300,\n",
      "         300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300,\n",
      "         300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300,\n",
      "         300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300,\n",
      "         300, 300]])\n",
      "Transcrição IPA para common_voice_ja_27816598.mp3: [PAD]\n",
      "\n",
      "[PAD]\n",
      "Processando arquivo: common_voice_ja_26978575.mp3\n",
      "Sampling rate do áudio: 32000\n",
      "Reamostrando o áudio para 16000Hz\n",
      "Tamanho do áudio (número de amostras): 67968\n",
      "tensor([[0.0003, 0.0003, 0.0003,  ..., 0.0003, 0.0004, 0.0003]])\n",
      "Forma do tensor de entrada: torch.Size([1, 67968])\n",
      "logits:  tensor([[[-0.7479, -0.5862, -0.5849,  ..., -0.9730, -0.9923,  5.1157],\n",
      "         [-0.7491, -0.6143, -0.5855,  ..., -0.9588, -0.9920,  5.1249],\n",
      "         [-0.7418, -0.6072, -0.5758,  ..., -0.9491, -1.0087,  5.1400],\n",
      "         ...,\n",
      "         [-0.7417, -0.6091, -0.5669,  ..., -0.9571, -1.0150,  5.1437],\n",
      "         [-0.7501, -0.6020, -0.5690,  ..., -0.9586, -1.0087,  5.1486],\n",
      "         [-0.7499, -0.6087, -0.5734,  ..., -0.9528, -1.0117,  5.1355]]])\n",
      "predicted_ids:  tensor([[300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300,\n",
      "         300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300,\n",
      "         300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300,\n",
      "         300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300,\n",
      "         300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300,\n",
      "         300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300,\n",
      "         300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300,\n",
      "         300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300,\n",
      "         300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300,\n",
      "         300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300,\n",
      "         300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300,\n",
      "         300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300,\n",
      "         300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300,\n",
      "         300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300,\n",
      "         300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300,\n",
      "         300, 300]])\n",
      "Transcrição IPA para common_voice_ja_26978575.mp3: [PAD]\n",
      "\n",
      "[PAD]\n",
      "Processando arquivo: common_voice_ja_24782890.mp3\n",
      "Sampling rate do áudio: 32000\n",
      "Reamostrando o áudio para 16000Hz\n",
      "Tamanho do áudio (número de amostras): 89856\n",
      "tensor([[ 0.0002,  0.0002,  0.0002,  ...,  0.0002, -0.0003, -0.0001]])\n",
      "Forma do tensor de entrada: torch.Size([1, 89856])\n",
      "logits:  tensor([[[-0.7468, -0.5912, -0.5884,  ..., -0.9769, -0.9880,  5.1126],\n",
      "         [-0.7518, -0.6113, -0.5816,  ..., -0.9620, -0.9866,  5.1187],\n",
      "         [-0.7362, -0.6198, -0.5670,  ..., -0.9515, -1.0005,  5.1333],\n",
      "         ...,\n",
      "         [-0.7474, -0.6055, -0.5633,  ..., -0.9609, -1.0047,  5.1426],\n",
      "         [-0.7382, -0.6069, -0.5735,  ..., -0.9641, -1.0025,  5.1362],\n",
      "         [-0.7336, -0.6001, -0.5639,  ..., -0.9578, -1.0047,  5.1321]]])\n",
      "predicted_ids:  tensor([[300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300,\n",
      "         300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300,\n",
      "         300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300,\n",
      "         300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300,\n",
      "         300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300,\n",
      "         300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300,\n",
      "         300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300,\n",
      "         300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300,\n",
      "         300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300,\n",
      "         300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300,\n",
      "         300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300,\n",
      "         300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300,\n",
      "         300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300,\n",
      "         300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300,\n",
      "         300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300,\n",
      "         300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300,\n",
      "         300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300,\n",
      "         300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300,\n",
      "         300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300,\n",
      "         300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300]])\n",
      "Transcrição IPA para common_voice_ja_24782890.mp3: [PAD]\n",
      "\n",
      "[PAD]\n",
      "Processando arquivo: common_voice_ja_22335166.mp3\n",
      "Sampling rate do áudio: 48000\n",
      "Reamostrando o áudio para 16000Hz\n",
      "Tamanho do áudio (número de amostras): 59904\n",
      "tensor([[-1.0873e-04, -1.0873e-04, -1.0873e-04,  ..., -9.7356e-05,\n",
      "         -6.6095e-05, -9.3818e-05]])\n",
      "Forma do tensor de entrada: torch.Size([1, 59904])\n",
      "logits:  tensor([[[-0.7431, -0.5881, -0.5857,  ..., -0.9768, -0.9847,  5.1178],\n",
      "         [-0.7535, -0.6116, -0.5938,  ..., -0.9659, -1.0017,  5.1379],\n",
      "         [-0.7578, -0.6023, -0.5917,  ..., -0.9536, -1.0054,  5.1410],\n",
      "         ...,\n",
      "         [-0.7556, -0.5911, -0.5880,  ..., -0.9567, -1.0156,  5.1467],\n",
      "         [-0.7514, -0.6027, -0.5895,  ..., -0.9584, -1.0235,  5.1413],\n",
      "         [-0.7421, -0.5881, -0.5830,  ..., -0.9530, -1.0230,  5.1374]]])\n",
      "predicted_ids:  tensor([[300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300,\n",
      "         300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300,\n",
      "         300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300,\n",
      "         300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300,\n",
      "         300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300,\n",
      "         300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300,\n",
      "         300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300,\n",
      "         300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300,\n",
      "         300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300,\n",
      "         300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300,\n",
      "         300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300,\n",
      "         300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300,\n",
      "         300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300,\n",
      "         300, 300, 300, 300]])\n",
      "Transcrição IPA para common_voice_ja_22335166.mp3: [PAD]\n",
      "\n",
      "[PAD]\n",
      "Processando arquivo: common_voice_ja_25960350.mp3\n",
      "Sampling rate do áudio: 32000\n",
      "Reamostrando o áudio para 16000Hz\n",
      "Tamanho do áudio (número de amostras): 65088\n",
      "tensor([[0.0003, 0.0003, 0.0003,  ..., 0.0004, 0.0003, 0.0004]])\n",
      "Forma do tensor de entrada: torch.Size([1, 65088])\n",
      "logits:  tensor([[[-0.7459, -0.5869, -0.5895,  ..., -0.9643, -0.9979,  5.1112],\n",
      "         [-0.7489, -0.6198, -0.5850,  ..., -0.9587, -0.9845,  5.1191],\n",
      "         [-0.7361, -0.6271, -0.5679,  ..., -0.9617, -0.9870,  5.1278],\n",
      "         ...,\n",
      "         [-0.7401, -0.6072, -0.5806,  ..., -0.9511, -1.0076,  5.1327],\n",
      "         [-0.7313, -0.6072, -0.5784,  ..., -0.9523, -1.0013,  5.1396],\n",
      "         [-0.7378, -0.6109, -0.5814,  ..., -0.9655, -1.0135,  5.1353]]])\n",
      "predicted_ids:  tensor([[300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300,\n",
      "         300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300,\n",
      "         300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300,\n",
      "         300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300,\n",
      "         300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300,\n",
      "         300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300,\n",
      "         300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300,\n",
      "         300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300,\n",
      "         300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300,\n",
      "         300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300,\n",
      "         300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300,\n",
      "         300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300,\n",
      "         300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300,\n",
      "         300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300,\n",
      "         300, 300, 300, 300, 300, 300, 300]])\n",
      "Transcrição IPA para common_voice_ja_25960350.mp3: [PAD]\n",
      "\n",
      "[PAD]\n",
      "Processando arquivo: common_voice_ja_33228037.mp3\n",
      "Sampling rate do áudio: 32000\n",
      "Reamostrando o áudio para 16000Hz\n",
      "Tamanho do áudio (número de amostras): 35136\n",
      "tensor([[-7.4957e-05, -7.4957e-05, -7.4957e-05,  ..., -7.4957e-05,\n",
      "         -7.4957e-05, -7.4957e-05]])\n",
      "Forma do tensor de entrada: torch.Size([1, 35136])\n",
      "logits:  tensor([[[-0.7430, -0.5945, -0.5862,  ..., -0.9718, -0.9966,  5.1267],\n",
      "         [-0.7577, -0.6108, -0.5970,  ..., -0.9692, -1.0079,  5.1421],\n",
      "         [-0.7616, -0.6098, -0.5981,  ..., -0.9637, -1.0090,  5.1460],\n",
      "         ...,\n",
      "         [-0.7608, -0.5982, -0.5930,  ..., -0.9605, -1.0110,  5.1478],\n",
      "         [-0.7599, -0.5980, -0.5933,  ..., -0.9620, -1.0129,  5.1476],\n",
      "         [-0.7497, -0.5972, -0.5912,  ..., -0.9600, -1.0160,  5.1427]]])\n",
      "predicted_ids:  tensor([[300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300,\n",
      "         300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300,\n",
      "         300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300,\n",
      "         300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300,\n",
      "         300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300,\n",
      "         300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300,\n",
      "         300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300,\n",
      "         300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300]])\n",
      "Transcrição IPA para common_voice_ja_33228037.mp3: [PAD]\n",
      "\n",
      "[PAD]\n",
      "Processando arquivo: common_voice_ja_28579978.mp3\n",
      "Sampling rate do áudio: 32000\n",
      "Reamostrando o áudio para 16000Hz\n",
      "Tamanho do áudio (número de amostras): 101376\n",
      "tensor([[-1.9423e-04, -1.9423e-04, -1.9423e-04,  ..., -1.2602e-04,\n",
      "         -4.4474e-04,  1.6415e-05]])\n",
      "Forma do tensor de entrada: torch.Size([1, 101376])\n",
      "logits:  tensor([[[-0.7452, -0.5871, -0.5811,  ..., -0.9654, -0.9840,  5.1084],\n",
      "         [-0.7547, -0.6123, -0.5981,  ..., -0.9594, -1.0000,  5.1199],\n",
      "         [-0.7619, -0.6162, -0.5910,  ..., -0.9536, -0.9976,  5.1263],\n",
      "         ...,\n",
      "         [-0.7425, -0.5894, -0.5777,  ..., -0.9576, -1.0132,  5.1456],\n",
      "         [-0.7434, -0.5882, -0.5754,  ..., -0.9509, -1.0141,  5.1420],\n",
      "         [-0.7424, -0.6140, -0.5710,  ..., -0.9438, -1.0075,  5.1330]]])\n",
      "predicted_ids:  tensor([[300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300,\n",
      "         300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300,\n",
      "         300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300,\n",
      "         300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300,\n",
      "         300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300,\n",
      "         300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300,\n",
      "         300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300,\n",
      "         300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300,\n",
      "         300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300,\n",
      "         300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300,\n",
      "         300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300,\n",
      "         300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300,\n",
      "         300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300,\n",
      "         300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300,\n",
      "         300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300,\n",
      "         300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300,\n",
      "         300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300,\n",
      "         300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300,\n",
      "         300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300,\n",
      "         300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300,\n",
      "         300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300,\n",
      "         300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300,\n",
      "         300, 300, 300, 300, 300, 300, 300, 300]])\n",
      "Transcrição IPA para common_voice_ja_28579978.mp3: [PAD]\n",
      "\n",
      "[PAD]\n",
      "Processando arquivo: common_voice_ja_21560731.mp3\n",
      "Sampling rate do áudio: 48000\n",
      "Reamostrando o áudio para 16000Hz\n",
      "Tamanho do áudio (número de amostras): 114816\n",
      "tensor([[0.0002, 0.0002, 0.0002,  ..., 0.0002, 0.0002, 0.0003]])\n",
      "Forma do tensor de entrada: torch.Size([1, 114816])\n",
      "logits:  tensor([[[-0.7517, -0.5899, -0.5799,  ..., -0.9718, -0.9916,  5.1135],\n",
      "         [-0.7459, -0.6090, -0.5813,  ..., -0.9527, -1.0035,  5.1345],\n",
      "         [-0.7402, -0.6029, -0.5756,  ..., -0.9439, -0.9952,  5.1321],\n",
      "         ...,\n",
      "         [-0.7475, -0.6021, -0.5611,  ..., -0.9584, -1.0007,  5.1382],\n",
      "         [-0.7481, -0.6053, -0.5618,  ..., -0.9534, -1.0101,  5.1393],\n",
      "         [-0.7306, -0.6033, -0.5570,  ..., -0.9527, -1.0150,  5.1265]]])\n",
      "predicted_ids:  tensor([[300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300,\n",
      "         300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300,\n",
      "         300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300,\n",
      "         300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300,\n",
      "         300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300,\n",
      "         300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300,\n",
      "         300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300,\n",
      "         300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300,\n",
      "         300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300,\n",
      "         300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300,\n",
      "         300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300,\n",
      "         300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300,\n",
      "         300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300,\n",
      "         300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300,\n",
      "         300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300,\n",
      "         300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300,\n",
      "         300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300,\n",
      "         300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300,\n",
      "         300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300,\n",
      "         300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300,\n",
      "         300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300,\n",
      "         300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300,\n",
      "         300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300,\n",
      "         300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300,\n",
      "         300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300,\n",
      "         300, 300, 300, 300, 300, 300, 300, 300]])\n",
      "Transcrição IPA para common_voice_ja_21560731.mp3: [PAD]\n",
      "\n",
      "[PAD]\n",
      "Processando arquivo: common_voice_ja_22342525.mp3\n",
      "Sampling rate do áudio: 48000\n",
      "Reamostrando o áudio para 16000Hz\n",
      "Tamanho do áudio (número de amostras): 88704\n",
      "tensor([[-4.2797e-04, -4.2797e-04, -4.2797e-04,  ..., -4.6767e-04,\n",
      "         -5.7040e-06,  7.1623e-04]])\n",
      "Forma do tensor de entrada: torch.Size([1, 88704])\n",
      "logits:  tensor([[[-0.7483, -0.5854, -0.5780,  ..., -0.9723, -0.9864,  5.1113],\n",
      "         [-0.7528, -0.6075, -0.5745,  ..., -0.9622, -1.0009,  5.1307],\n",
      "         [-0.7463, -0.6088, -0.5729,  ..., -0.9513, -0.9981,  5.1344],\n",
      "         ...,\n",
      "         [-0.7568, -0.6083, -0.5639,  ..., -0.9573, -0.9953,  5.1379],\n",
      "         [-0.7603, -0.5972, -0.5695,  ..., -0.9548, -1.0007,  5.1402],\n",
      "         [-0.7390, -0.6025, -0.5710,  ..., -0.9556, -1.0023,  5.1329]]])\n",
      "predicted_ids:  tensor([[300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300,\n",
      "         300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300,\n",
      "         300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300,\n",
      "         300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300,\n",
      "         300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300,\n",
      "         300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300,\n",
      "         300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300,\n",
      "         300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300,\n",
      "         300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300,\n",
      "         300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300,\n",
      "         300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300,\n",
      "         300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300,\n",
      "         300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300,\n",
      "         300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300,\n",
      "         300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300,\n",
      "         300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300,\n",
      "         300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300,\n",
      "         300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300,\n",
      "         300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300,\n",
      "         300, 300, 300, 300, 300, 300, 300, 300, 300, 300]])\n",
      "Transcrição IPA para common_voice_ja_22342525.mp3: [PAD]\n",
      "\n",
      "[PAD]\n",
      "Processando arquivo: common_voice_ja_20967454.mp3\n",
      "Sampling rate do áudio: 48000\n",
      "Reamostrando o áudio para 16000Hz\n",
      "Tamanho do áudio (número de amostras): 99456\n",
      "tensor([[0.0006, 0.0006, 0.0006,  ..., 0.0006, 0.0006, 0.0006]])\n",
      "Forma do tensor de entrada: torch.Size([1, 99456])\n",
      "logits:  tensor([[[-0.7427, -0.5883, -0.5826,  ..., -0.9674, -0.9883,  5.1105],\n",
      "         [-0.7592, -0.6097, -0.5982,  ..., -0.9507, -1.0134,  5.1355],\n",
      "         [-0.7616, -0.6050, -0.5919,  ..., -0.9508, -1.0109,  5.1415],\n",
      "         ...,\n",
      "         [-0.7643, -0.5881, -0.5900,  ..., -0.9458, -1.0116,  5.1459],\n",
      "         [-0.7650, -0.5853, -0.5896,  ..., -0.9526, -1.0113,  5.1462],\n",
      "         [-0.7506, -0.5887, -0.5940,  ..., -0.9527, -1.0106,  5.1364]]])\n",
      "predicted_ids:  tensor([[300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300,\n",
      "         300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300,\n",
      "         300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300,\n",
      "         300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300,\n",
      "         300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300,\n",
      "         300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300,\n",
      "         300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300,\n",
      "         300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300,\n",
      "         300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300,\n",
      "         300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300,\n",
      "         300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300,\n",
      "         300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300,\n",
      "         300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300,\n",
      "         300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300,\n",
      "         300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300,\n",
      "         300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300,\n",
      "         300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300,\n",
      "         300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300,\n",
      "         300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300,\n",
      "         300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300,\n",
      "         300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300,\n",
      "         300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300,\n",
      "         300, 300]])\n",
      "Transcrição IPA para common_voice_ja_20967454.mp3: [PAD]\n",
      "\n",
      "[PAD]\n",
      "Processando arquivo: common_voice_ja_21358328.mp3\n",
      "Sampling rate do áudio: 48000\n",
      "Reamostrando o áudio para 16000Hz\n",
      "Tamanho do áudio (número de amostras): 91008\n",
      "tensor([[-0.0007, -0.0007, -0.0007,  ..., -0.0005, -0.0007, -0.0008]])\n",
      "Forma do tensor de entrada: torch.Size([1, 91008])\n",
      "logits:  tensor([[[-0.7494, -0.5818, -0.5793,  ..., -0.9763, -0.9947,  5.1094],\n",
      "         [-0.7490, -0.6005, -0.5858,  ..., -0.9590, -1.0137,  5.1407],\n",
      "         [-0.7435, -0.5950, -0.5685,  ..., -0.9522, -0.9990,  5.1381],\n",
      "         ...,\n",
      "         [-0.7395, -0.5969, -0.5696,  ..., -0.9589, -1.0035,  5.1417],\n",
      "         [-0.7350, -0.5963, -0.5696,  ..., -0.9646, -1.0055,  5.1412],\n",
      "         [-0.7377, -0.6043, -0.5713,  ..., -0.9556, -1.0075,  5.1309]]])\n",
      "predicted_ids:  tensor([[300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300,\n",
      "         300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300,\n",
      "         300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300,\n",
      "         300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300,\n",
      "         300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300,\n",
      "         300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300,\n",
      "         300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300,\n",
      "         300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300,\n",
      "         300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300,\n",
      "         300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300,\n",
      "         300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300,\n",
      "         300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300,\n",
      "         300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300,\n",
      "         300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300,\n",
      "         300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300,\n",
      "         300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300,\n",
      "         300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300,\n",
      "         300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300,\n",
      "         300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300,\n",
      "         300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300,\n",
      "         300, 300, 300, 300]])\n",
      "Transcrição IPA para common_voice_ja_21358328.mp3: [PAD]\n",
      "\n",
      "[PAD]\n",
      "Processando arquivo: common_voice_ja_31183368.mp3\n",
      "Sampling rate do áudio: 32000\n",
      "Reamostrando o áudio para 16000Hz\n",
      "Tamanho do áudio (número de amostras): 66240\n",
      "tensor([[0.0010, 0.0010, 0.0010,  ..., 0.0010, 0.0010, 0.0010]])\n",
      "Forma do tensor de entrada: torch.Size([1, 66240])\n",
      "logits:  tensor([[[-0.7456, -0.5939, -0.5878,  ..., -0.9771, -0.9873,  5.1167],\n",
      "         [-0.7600, -0.6138, -0.5985,  ..., -0.9627, -1.0019,  5.1314],\n",
      "         [-0.7481, -0.6110, -0.5876,  ..., -0.9488, -1.0135,  5.1380],\n",
      "         ...,\n",
      "         [-0.7621, -0.5941, -0.5874,  ..., -0.9541, -1.0105,  5.1444],\n",
      "         [-0.7588, -0.5964, -0.5943,  ..., -0.9534, -1.0148,  5.1404],\n",
      "         [-0.7457, -0.5938, -0.5874,  ..., -0.9657, -1.0073,  5.1358]]])\n",
      "predicted_ids:  tensor([[300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300,\n",
      "         300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300,\n",
      "         300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300,\n",
      "         300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300,\n",
      "         300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300,\n",
      "         300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300,\n",
      "         300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300,\n",
      "         300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300,\n",
      "         300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300,\n",
      "         300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300,\n",
      "         300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300,\n",
      "         300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300,\n",
      "         300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300,\n",
      "         300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300,\n",
      "         300, 300, 300, 300, 300, 300, 300, 300, 300, 300]])\n",
      "Transcrição IPA para common_voice_ja_31183368.mp3: [PAD]\n",
      "\n",
      "[PAD]\n",
      "Processando arquivo: common_voice_ja_27700046.mp3\n",
      "Sampling rate do áudio: 32000\n",
      "Reamostrando o áudio para 16000Hz\n",
      "Tamanho do áudio (número de amostras): 75456\n",
      "tensor([[-1.3832e-05, -1.3832e-05, -1.3832e-05,  ...,  3.8026e-05,\n",
      "          5.2491e-05,  5.7302e-05]])\n",
      "Forma do tensor de entrada: torch.Size([1, 75456])\n",
      "logits:  tensor([[[-0.7439, -0.5896, -0.5844,  ..., -0.9733, -0.9930,  5.1147],\n",
      "         [-0.7489, -0.6105, -0.5963,  ..., -0.9735, -1.0030,  5.1324],\n",
      "         [-0.7558, -0.6160, -0.5950,  ..., -0.9668, -1.0003,  5.1329],\n",
      "         ...,\n",
      "         [-0.7502, -0.6047, -0.5751,  ..., -0.9521, -1.0058,  5.1436],\n",
      "         [-0.7496, -0.6090, -0.5762,  ..., -0.9520, -1.0162,  5.1440],\n",
      "         [-0.7478, -0.6097, -0.5726,  ..., -0.9513, -1.0110,  5.1401]]])\n",
      "predicted_ids:  tensor([[300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300,\n",
      "         300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300,\n",
      "         300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300,\n",
      "         300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300,\n",
      "         300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300,\n",
      "         300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300,\n",
      "         300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300,\n",
      "         300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300,\n",
      "         300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300,\n",
      "         300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300,\n",
      "         300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300,\n",
      "         300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300,\n",
      "         300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300,\n",
      "         300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300,\n",
      "         300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300,\n",
      "         300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300,\n",
      "         300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300]])\n",
      "Transcrição IPA para common_voice_ja_27700046.mp3: [PAD]\n",
      "\n",
      "[PAD]\n",
      "Processando arquivo: common_voice_ja_29378016.mp3\n",
      "Sampling rate do áudio: 32000\n",
      "Reamostrando o áudio para 16000Hz\n",
      "Tamanho do áudio (número de amostras): 63936\n",
      "tensor([[ 0.0005,  0.0005,  0.0005,  ...,  0.0007,  0.0006, -0.0002]])\n",
      "Forma do tensor de entrada: torch.Size([1, 63936])\n",
      "logits:  tensor([[[-0.7441, -0.5952, -0.5835,  ..., -0.9731, -0.9873,  5.1143],\n",
      "         [-0.7470, -0.6155, -0.5789,  ..., -0.9548, -0.9959,  5.1249],\n",
      "         [-0.7364, -0.6121, -0.5846,  ..., -0.9517, -1.0067,  5.1421],\n",
      "         ...,\n",
      "         [-0.7341, -0.6004, -0.5605,  ..., -0.9510, -1.0139,  5.1472],\n",
      "         [-0.7372, -0.6137, -0.5718,  ..., -0.9555, -1.0105,  5.1389],\n",
      "         [-0.7242, -0.6057, -0.5623,  ..., -0.9544, -1.0109,  5.1354]]])\n",
      "predicted_ids:  tensor([[300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300,\n",
      "         300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300,\n",
      "         300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300,\n",
      "         300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300,\n",
      "         300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300,\n",
      "         300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300,\n",
      "         300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300,\n",
      "         300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300,\n",
      "         300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300,\n",
      "         300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300,\n",
      "         300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300,\n",
      "         300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300,\n",
      "         300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300,\n",
      "         300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300,\n",
      "         300, 300, 300]])\n",
      "Transcrição IPA para common_voice_ja_29378016.mp3: [PAD]\n",
      "\n",
      "[PAD]\n",
      "Processando arquivo: common_voice_ja_32408912.mp3\n",
      "Sampling rate do áudio: 32000\n",
      "Reamostrando o áudio para 16000Hz\n",
      "Tamanho do áudio (número de amostras): 63936\n",
      "tensor([[ 0.0002,  0.0002,  0.0002,  ...,  0.0003, -0.0002, -0.0001]])\n",
      "Forma do tensor de entrada: torch.Size([1, 63936])\n",
      "logits:  tensor([[[-0.7516, -0.5958, -0.5829,  ..., -0.9854, -0.9930,  5.1180],\n",
      "         [-0.7476, -0.6190, -0.5798,  ..., -0.9751, -0.9871,  5.1195],\n",
      "         [-0.7353, -0.6126, -0.5688,  ..., -0.9553, -0.9951,  5.1331],\n",
      "         ...,\n",
      "         [-0.7328, -0.6013, -0.5689,  ..., -0.9545, -1.0047,  5.1403],\n",
      "         [-0.7351, -0.5990, -0.5719,  ..., -0.9631, -1.0033,  5.1375],\n",
      "         [-0.7265, -0.5982, -0.5633,  ..., -0.9550, -1.0073,  5.1348]]])\n",
      "predicted_ids:  tensor([[300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300,\n",
      "         300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300,\n",
      "         300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300,\n",
      "         300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300,\n",
      "         300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300,\n",
      "         300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300,\n",
      "         300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300,\n",
      "         300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300,\n",
      "         300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300,\n",
      "         300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300,\n",
      "         300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300,\n",
      "         300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300,\n",
      "         300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300,\n",
      "         300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300,\n",
      "         300, 300, 300]])\n",
      "Transcrição IPA para common_voice_ja_32408912.mp3: [PAD]\n",
      "\n",
      "[PAD]\n",
      "Processando arquivo: common_voice_ja_27697257.mp3\n",
      "Sampling rate do áudio: 32000\n",
      "Reamostrando o áudio para 16000Hz\n",
      "Tamanho do áudio (número de amostras): 103104\n",
      "tensor([[ 7.9663e-05,  7.9663e-05,  7.9663e-05,  ..., -1.8112e-04,\n",
      "          6.7036e-04,  5.2721e-04]])\n",
      "Forma do tensor de entrada: torch.Size([1, 103104])\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 39\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mProcessando arquivo: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfilename\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     38\u001b[0m \u001b[38;5;66;03m# Transcrever o áudio\u001b[39;00m\n\u001b[0;32m---> 39\u001b[0m ipa_transcription \u001b[38;5;241m=\u001b[39m \u001b[43mtranscribe_audio_to_ipa\u001b[49m\u001b[43m(\u001b[49m\u001b[43maudio_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     41\u001b[0m \u001b[38;5;66;03m# Exibir a transcrição IPA\u001b[39;00m\n\u001b[1;32m     42\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTranscrição IPA para \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfilename\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mipa_transcription\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[4], line 17\u001b[0m, in \u001b[0;36mtranscribe_audio_to_ipa\u001b[0;34m(audio_path)\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;66;03m# Fazer a predição\u001b[39;00m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m---> 17\u001b[0m     logits \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_values\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mlogits\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlogits: \u001b[39m\u001b[38;5;124m\"\u001b[39m,logits)\n\u001b[1;32m     20\u001b[0m \u001b[38;5;66;03m# Obter os índices das previsões\u001b[39;00m\n",
      "File \u001b[0;32m/mnt/5fc7fd01-6487-4f39-8109-556023ff1f7f/puc/7 sem/topicos/multipa/venv/lib/python3.9/site-packages/torch/nn/modules/module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1106\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1107\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1108\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1111\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1112\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m/mnt/5fc7fd01-6487-4f39-8109-556023ff1f7f/puc/7 sem/topicos/multipa/venv/lib/python3.9/site-packages/transformers/models/wav2vec2/modeling_wav2vec2.py:1684\u001b[0m, in \u001b[0;36mWav2Vec2ForCTC.forward\u001b[0;34m(self, input_values, attention_mask, output_attentions, output_hidden_states, return_dict, labels)\u001b[0m\n\u001b[1;32m   1674\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1675\u001b[0m \u001b[38;5;124;03mlabels (`torch.LongTensor` of shape `(batch_size, target_length)`, *optional*):\u001b[39;00m\n\u001b[1;32m   1676\u001b[0m \u001b[38;5;124;03m    Labels for connectionist temporal classification. Note that `target_length` has to be smaller or equal to\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1679\u001b[0m \u001b[38;5;124;03m    config.vocab_size - 1]`.\u001b[39;00m\n\u001b[1;32m   1680\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1682\u001b[0m return_dict \u001b[38;5;241m=\u001b[39m return_dict \u001b[38;5;28;01mif\u001b[39;00m return_dict \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39muse_return_dict\n\u001b[0;32m-> 1684\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwav2vec2\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1685\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1686\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1687\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1688\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1689\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1690\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1692\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m   1693\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout(hidden_states)\n",
      "File \u001b[0;32m/mnt/5fc7fd01-6487-4f39-8109-556023ff1f7f/puc/7 sem/topicos/multipa/venv/lib/python3.9/site-packages/torch/nn/modules/module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1106\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1107\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1108\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1111\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1112\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m/mnt/5fc7fd01-6487-4f39-8109-556023ff1f7f/puc/7 sem/topicos/multipa/venv/lib/python3.9/site-packages/transformers/models/wav2vec2/modeling_wav2vec2.py:1318\u001b[0m, in \u001b[0;36mWav2Vec2Model.forward\u001b[0;34m(self, input_values, attention_mask, mask_time_indices, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1313\u001b[0m hidden_states, extract_features \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfeature_projection(extract_features)\n\u001b[1;32m   1314\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_mask_hidden_states(\n\u001b[1;32m   1315\u001b[0m     hidden_states, mask_time_indices\u001b[38;5;241m=\u001b[39mmask_time_indices, attention_mask\u001b[38;5;241m=\u001b[39mattention_mask\n\u001b[1;32m   1316\u001b[0m )\n\u001b[0;32m-> 1318\u001b[0m encoder_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoder\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1319\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1320\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1321\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1322\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1323\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1324\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1326\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m encoder_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m   1328\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39madapter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m/mnt/5fc7fd01-6487-4f39-8109-556023ff1f7f/puc/7 sem/topicos/multipa/venv/lib/python3.9/site-packages/torch/nn/modules/module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1106\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1107\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1108\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1111\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1112\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m/mnt/5fc7fd01-6487-4f39-8109-556023ff1f7f/puc/7 sem/topicos/multipa/venv/lib/python3.9/site-packages/transformers/models/wav2vec2/modeling_wav2vec2.py:890\u001b[0m, in \u001b[0;36mWav2Vec2EncoderStableLayerNorm.forward\u001b[0;34m(self, hidden_states, attention_mask, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    884\u001b[0m         layer_outputs \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mcheckpoint\u001b[38;5;241m.\u001b[39mcheckpoint(\n\u001b[1;32m    885\u001b[0m             create_custom_forward(layer),\n\u001b[1;32m    886\u001b[0m             hidden_states,\n\u001b[1;32m    887\u001b[0m             attention_mask,\n\u001b[1;32m    888\u001b[0m         )\n\u001b[1;32m    889\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 890\u001b[0m         layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[43mlayer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    891\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\n\u001b[1;32m    892\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    893\u001b[0m     hidden_states \u001b[38;5;241m=\u001b[39m layer_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    895\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m skip_the_layer:\n",
      "File \u001b[0;32m/mnt/5fc7fd01-6487-4f39-8109-556023ff1f7f/puc/7 sem/topicos/multipa/venv/lib/python3.9/site-packages/torch/nn/modules/module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1106\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1107\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1108\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1111\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1112\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m/mnt/5fc7fd01-6487-4f39-8109-556023ff1f7f/puc/7 sem/topicos/multipa/venv/lib/python3.9/site-packages/transformers/models/wav2vec2/modeling_wav2vec2.py:727\u001b[0m, in \u001b[0;36mWav2Vec2EncoderLayerStableLayerNorm.forward\u001b[0;34m(self, hidden_states, attention_mask, output_attentions)\u001b[0m\n\u001b[1;32m    725\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout(hidden_states)\n\u001b[1;32m    726\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m attn_residual \u001b[38;5;241m+\u001b[39m hidden_states\n\u001b[0;32m--> 727\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m hidden_states \u001b[38;5;241m+\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfeed_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfinal_layer_norm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    729\u001b[0m outputs \u001b[38;5;241m=\u001b[39m (hidden_states,)\n\u001b[1;32m    731\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m output_attentions:\n",
      "File \u001b[0;32m/mnt/5fc7fd01-6487-4f39-8109-556023ff1f7f/puc/7 sem/topicos/multipa/venv/lib/python3.9/site-packages/torch/nn/modules/module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1106\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1107\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1108\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1111\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1112\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m/mnt/5fc7fd01-6487-4f39-8109-556023ff1f7f/puc/7 sem/topicos/multipa/venv/lib/python3.9/site-packages/transformers/models/wav2vec2/modeling_wav2vec2.py:657\u001b[0m, in \u001b[0;36mWav2Vec2FeedForward.forward\u001b[0;34m(self, hidden_states)\u001b[0m\n\u001b[1;32m    656\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, hidden_states):\n\u001b[0;32m--> 657\u001b[0m     hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mintermediate_dense\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    658\u001b[0m     hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mintermediate_act_fn(hidden_states)\n\u001b[1;32m    659\u001b[0m     hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mintermediate_dropout(hidden_states)\n",
      "File \u001b[0;32m/mnt/5fc7fd01-6487-4f39-8109-556023ff1f7f/puc/7 sem/topicos/multipa/venv/lib/python3.9/site-packages/torch/nn/modules/module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1106\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1107\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1108\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1111\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1112\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m/mnt/5fc7fd01-6487-4f39-8109-556023ff1f7f/puc/7 sem/topicos/multipa/venv/lib/python3.9/site-packages/torch/nn/modules/linear.py:103\u001b[0m, in \u001b[0;36mLinear.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 103\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def transcribe_audio_to_ipa(audio_path):\n",
    "    # Carregar e processar o áudio\n",
    "    audio = load_and_process_audio(audio_path)\n",
    "\n",
    "    # Verificar se o áudio tem o tamanho adequado para o modelo\n",
    "    print(f\"Tamanho do áudio (número de amostras): {len(audio)}\")\n",
    "\n",
    "    # Processar o áudio para o modelo\n",
    "    input_values = processor(audio, return_tensors=\"pt\", sampling_rate=16000).input_values\n",
    "    print(input_values)\n",
    "\n",
    "    # Verificar a forma do tensor de entrada\n",
    "    print(f\"Forma do tensor de entrada: {input_values.shape}\")\n",
    "\n",
    "    # Fazer a predição\n",
    "    with torch.no_grad():\n",
    "        logits = model(input_values).logits\n",
    "    print(\"logits: \",logits)\n",
    "\n",
    "    # Obter os índices das previsões\n",
    "    predicted_ids = torch.argmax(logits, dim=-1)\n",
    "    print(\"predicted_ids: \",predicted_ids)\n",
    "\n",
    "    # Decodificar para IPA (usando o processor.decode diretamente)\n",
    "    transcription = processor.decode(predicted_ids[0])  # Usando o método decode diretamente no primeiro item\n",
    "\n",
    "    return transcription\n",
    "\n",
    "# Caminho da pasta contendo os arquivos de áudio\n",
    "audio_folder = '/mnt/5fc7fd01-6487-4f39-8109-556023ff1f7f/puc/7 sem/topicos/multipa/cache/downloads/extracted/def0c51c4e5eae516227b49db5a07980edbfac43a9b8402e9f3b33954f29661d/ja_test_0/'\n",
    "\n",
    "# Iterar sobre todos os arquivos de áudio na pasta\n",
    "for filename in os.listdir(audio_folder):\n",
    "    if filename.endswith(\".mp3\"):  # Verificar se é um arquivo mp3\n",
    "        audio_path = os.path.join(audio_folder, filename)\n",
    "        print(f\"Processando arquivo: {filename}\")\n",
    "        \n",
    "        ipa_transcription = transcribe_audio_to_ipa(audio_path)\n",
    "\n",
    "        print(f\"Transcrição IPA para {filename}: {ipa_transcription}\\n\")\n",
    "\n",
    "        if(ipa_transcription != \"[IPA]\"):\n",
    "            print(ipa_transcription)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Testing language: ja\n",
      "Dataset ja carregado do cache.\n",
      "Sample 1: [PAD]\n",
      "Sample 2: [PAD]\n"
     ]
    }
   ],
   "source": [
    "# Exibir os resultados\n",
    "languages = [\"ja\", \"pl\", \"mt\", \"hu\", \"fi\", \"el\"]\n",
    "num_samples = 5\n",
    "\n",
    "results = test_model_on_samples(model_dir, languages, num_samples, cache_dir)\n",
    "\n",
    "for lang, metrics in results.items():\n",
    "    print(f\"\\nResults for {lang}:\")\n",
    "    print(f\"PER: {metrics['per']:.4f}\")\n",
    "    print(f\"PFER: {metrics['pfer']:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
